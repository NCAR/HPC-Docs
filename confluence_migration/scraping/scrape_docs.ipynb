{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2c4e4-f914-44c4-bbdd-9ca473fdbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import requests_cache\n",
    "# importing re module\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "requests_cache.install_cache(cache_name='kb_cache', backend='sqlite', expire_after=datetime.timedelta(hours=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea6e1eb-87c0-467c-883d-5867779620d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocPage:\n",
    "    \"\"\"Simple Class to hold documentation pages & metadata.\"\"\"\n",
    "    \n",
    "    max_title_len = 50\n",
    "    \n",
    "    def __init__(self, name, url):\n",
    "        \n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.html = None\n",
    "        self.word_export = None\n",
    "        self.author = \"\"\n",
    "        self.last_mod_date = \"\"\n",
    "        self.last_mod_user = \"\"\n",
    "        self.last_review_date = \"\"\n",
    "        self.last_review_user = \"\"\n",
    "        self.from_cache = False\n",
    "        \n",
    "        page = requests.get(self.url)\n",
    "        self.from_cache = page.from_cache        \n",
    "        self.html = page.content\n",
    "        soup = BeautifulSoup(self.html, \"html.parser\")\n",
    "    \n",
    "        le = soup.find(\"span\", {\"class\": \"author\"})\n",
    "        if le: \n",
    "            self.author = le.text.strip()\n",
    "            self.last_mod_user = le.text.strip()\n",
    "        le = soup.find(\"span\", {\"class\": \"editor\"})\n",
    "        if le: \n",
    "            self.last_mod_user = le.text.strip()\n",
    "    \n",
    "        lm = soup.find(\"a\", {\"class\": \"last-modified\"}) \n",
    "        lm_date  = lm.text.strip()        \n",
    "        self.last_mod_date = lm_date\n",
    "        \n",
    "        lm = soup.find(\"a\", {\"class\": \"action-export-word\"}) \n",
    "        self.word_export = kb_url + lm['href']\n",
    "        \n",
    "        # if we downloaded the page, vs. reading from Cache, sleep a bit\n",
    "        if not self.from_cache:\n",
    "            time.sleep(0.2)\n",
    "                \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def get_info(self):\n",
    "        info = \"{0}\\n{1}\\nLast Modified: {2}, Author: {3}, Last Editor: {4}\\n  From Cache={5}\\n Word={6}\".format(self.name, self.url,\n",
    "                                                                                                                 self.last_mod_date, self.author, self.last_mod_user,\n",
    "                                                                                                                 self.from_cache, self.word_export)\n",
    "                                                                   \n",
    "        return info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16dde6-430c-4890-93ed-dfa73267f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
    "kb_url = \"https://kb.ucar.edu\"\n",
    "url = kb_url + \"/display/RC\"\n",
    "kb_page = DocPage(\"Research Computing Knowledge Base\", url)\n",
    "print(kb_page.get_info())\n",
    "#page = urlopen(url)\n",
    "#html = page.read().decode(\"utf-8\")\n",
    "html = kb_page.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505dea99-09d6-4017-b65f-d4ca02c619db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(soup.find_all(\"a\")))\n",
    "a_hrefs = [x for x in soup.find_all(\"a\") if \"/display/RC\" in str(x) and \"title\" not in str(x)]\n",
    "titles =  [x.text for x in a_hrefs]\n",
    "maxw = len(max(titles, key = len))\n",
    "DocPage.max_title_len = maxw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050e8df-0399-4d4e-a3cd-6c881c937f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Title\": titles,\n",
    "        \"URL\": \"\",\n",
    "        \"Word Export\": \"\",\n",
    "        \"Author\": \"\",\n",
    "        \"Last Modification\": pd.Timestamp(\"20010102\"),\n",
    "        \"Last Editor\": \"\",\n",
    "        \"Last Review\": pd.Timestamp(\"20010102\"),\n",
    "        \"Last Reviewer\": \"\",\n",
    "    },\n",
    "    index=titles,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de1642-ae01-498c-9804-8943459f9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(a_hrefs), type(a_hrefs))\n",
    "#print(links)\n",
    "#print(maxw, titles)\n",
    "\n",
    "idx=0\n",
    "for l in a_hrefs:\n",
    "    s = str(l)\n",
    "    #print(s)\n",
    "    \n",
    "    #print(type(l))\n",
    "    #print(l.attrs)\n",
    "    \n",
    "    page_url = kb_url + l[\"href\"]\n",
    "    \n",
    "    foo = DocPage(l.text, page_url)    \n",
    "    if idx < 5: print(foo.get_info() + '\\n')\n",
    "    \n",
    "    #print([x for x in l.strings])\n",
    "    \n",
    "    title = foo.name\n",
    "    df.at[title, \"Title\"]               = foo.name\n",
    "    df.at[title, \"URL\"]                 = foo.url\n",
    "    df.at[title, \"Word Export\"]         = foo.word_export\n",
    "    df.at[title, \"Author\"]              = foo.author\n",
    "    df.at[title, \"Last Editor\"]         = foo.last_mod_user\n",
    "    try:\n",
    "        df.at[title, \"Last Modification\"] = pd.Timestamp(foo.last_mod_date)\n",
    "    except:\n",
    "        df.at[title, \"Last Modification\"] = pd.Timestamp(datetime.datetime.now())\n",
    "\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2a0f2-6dd3-4dd4-917e-119727eef7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08daac9-5c6b-4b00-92e2-c75c0b945db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9ba9c-4980-4185-a18c-54c00dcec548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(r'hpc_docs_pages.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab884da-8462-41e1-8cff-a26d65da79a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
